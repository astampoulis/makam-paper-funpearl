\documentclass[format=acmlarge,review,anonymous]{acmart}\settopmatter{printfolios=true}

\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{alltt}
\usepackage{xspace}

\bibliographystyle{shared/ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations

\makeatletter\if@ACM@journal\makeatother
%% Journal information (used by PACMPL format)
%% Supplied to authors by publisher for camera-ready submission
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{1}
\acmArticle{1}
\acmYear{2017}
\acmMonth{1}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\else\makeatother
%% Conference information (used by SIGPLAN proceedings format)
%% Supplied to authors by publisher for camera-ready submission
\acmConference[PL'17]{ACM SIGPLAN Conference on Programming Languages}{January 01--03, 2017}{New York, NY, USA}
\acmYear{2017}
\acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\fi


\begin{document}

\title{Makam}
\subtitle{Functional Pearl}

\author{Antonis Stampoulis}
\affiliation{
  \institution{Originate Inc.}
  \city{New York}
  \state{New York}
}
\email{antonis.stampoulis@gmail.com}

\author{Adam Chlipala}
\affiliation{
  \department{CSAIL}
  \institution{MIT}
  \city{Cambridge}
  \state{Massachusetts}
}
\email{adamc@csail.mit.edu}

%% -- Macro definitions
\newcommand\TODO[0]{\textbf{TODO}}
\newcommand\lamprolog[0]{$\lambda$Prolog\xspace}
\newcommand\fomega[0]{F$\omega$\xspace}
\newenvironment{codequote}{\begin{quote}\begin{alltt}}{\end{alltt}\end{quote}}

\begin{abstract}
\TODO{} This is the abstract of the paper.
\end{abstract}

%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
%% \begin{CCSXML}
%% <ccs2012>
%% <concept>
%% <concept_id>10011007.10011006.10011008</concept_id>
%% <concept_desc>Software and its engineering~General programming languages</concept_desc>
%% <concept_significance>500</concept_significance>
%% </concept>
%% <concept>
%% <concept_id>10003456.10003457.10003521.10003525</concept_id>
%% <concept_desc>Social and professional topics~History of programming languages</concept_desc>
%% <concept_significance>300</concept_significance>
%% </concept>
%% </ccs2012>
%% \end{CCSXML}

%% \ccsdesc[500]{Software and its engineering~General programming languages}
%% \ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code

\maketitle


%% === Introduction

\section{Introduction}

\TODO{} This is the introduction. We will cite the work by \citet{miller1988overview} here.

% === Simple functional language

\section{Starting out simple}

We will start by encoding a version of the simply typed lambda calculus in \lamprolog. We define two
new meta-types to represent the two sorts of our object language: terms and types. We also define
the \texttt{typeof} relation that corresponds to the typing judgement of the language.
\begin{codequote}
term   : type.
typ    : type.
typeof : term -> typ -> prop.
\end{codequote}

Defining the basic forms of the lambda calculus is easy, thanks to the support of higher-order
abstract syntax in higher-order logic programming. We can reuse the meta-level function type in
order to implement object-level binding. This is because the meta-level function space is
\textit{parametric} -- that is, the body of a function is a value that can just mention the argument
as-is, instead of being a computation that can inspect the specific value of an argument. Therefore,
meta-level functions exactly represent an object-level binding of a single variable, without
introducing \textit{exotic terms}.

\begin{codequote}
app    : term -> term -> term.
lam    : typ -> (term -> term) -> term.
arrow  : typ -> typ -> typ.
\end{codequote}

Encoding the typing rule for application as a \lamprolog \textit{clause} for the \texttt{typeof} relation is a
straightforward transliteration of the pen-and-paper version.

\begin{codequote}
typeof (app E1 E2) T' :-
  typeof E1 (arrow T T'),
  typeof E2 T.
\end{codequote}

In logic programming, the goal of a rule is written first, followed by the premises; the \texttt{:-}
operator can be read as "is implied by," and comma is logical conjuction. We use capital letters for
unification variables.

The rule for lambda functions is similarly straightforward: 

\begin{codequote}
typeof (lam T1 E) (arrow T1 T2) :-
  (x:term -> typeof x T1 -> typeof (E x) T2).
\end{codequote}

There are three things of note in the premise of the rule. First, we introduce a fresh term variable
\texttt{x}, through the form \texttt{x:term ->}, which can be read as universal quantification. Second, we
introduce a new assumption through the form \texttt{typeof x T ->}, which essentially introduces a new rule
for the \texttt{typeof} relation locally; this can be read as logical implication. Third, in order to get
to the body of the lambda function to type-check it, we need to apply it to the fresh variable \texttt{x}.

With these definitions, we have already implemented a type-checker for the simply typed lambda
calculus, as we can issue queries for the \texttt{typeof} relation to Makam:

\begin{codequote}
typeof (lam _ (fun x => x)) T' ?
>> Yes:
>> T' := arrow T T
\end{codequote}

One benefit of using \lamprolog instead of rolling our own type-checker is that the occurs check is
already implemented in the unification engine. As a result, a query that would result in an
ill-formed cyclical type with a naive implementation of unification fails as expected.

\begin{codequote}
typeof (lam _ (fun x => app x x)) T' ?
>> Impossible.
\end{codequote}

Other than supporting higher-order abstract syntax, \lamprolog also supports polymorphic types and
higher-order predicates, in a matter akin to traditional functional programming languages. For
example, we can define the polymorphic \texttt{list} type, and an accompanying \texttt{map}
higher-order predicate, as follows:

\begin{codequote}
list : type -> type.

nil : list A.
cons : A -> list A -> list A.

map : (A -> B -> prop) -> list A -> list B -> prop.
map P nil nil.
map P (cons X XS) (cons Y YS) :- P X Y, map P XS YS.
\end{codequote}

Using the meta-level \texttt{list} type, we can encode object-level constructs such as tuples and product
types directly:

\begin{codequote}
tuple : list term -> term.
product : list typ -> typ.
\end{codequote}

Similarly we can use the \texttt{map} predicate to define the typing relation for tuples. 

\begin{codequote}
typeof (tuple ES) (product TS) :-
  map typeof ES TS.
\end{codequote}

Executing a query with a tuple yields the right result:

\begin{codequote}
typeof (lam _ (fun x => lam _ (fun y => tuple (cons x (cons y nil))))) T ?
>> Yes:
>> T := arrow T1 (arrow T2 (product (cons T1 (cons T2 nil))))
\end{codequote}

So far we have only introduced the predicate \texttt{typeof} for typing. In the same way, we can introduce
a predicate for evaluating terms, capturing the dynamic semantics of the language.

\begin{codequote}
eval : term -> term -> prop.
\end{codequote}

Most of the rules are straightforward, following standard practice for big-step semantics.  We
assume a call-by-value evaluation strategy.

\begin{codequote}
eval (lam T F) (lam T F).
eval (tuple ES) (tuple VS) :- map eval ES VS.
\end{codequote}

For the beta-redex case, function application for higher-order abstract syntax gives us
capture-avoiding substitution directly:

\begin{codequote}
eval (app E E') V'' :-
  eval E (lam _ F), eval E' V', eval (F V') V''.
\end{codequote}

%% === Multiple variable binding

\section{Multiple variable binding}

As we've seen, single-variable binding as in the lambda abstraction can
be handled easily through higher-order abstract syntax. Let us now
explore how to encode other forms of binding.

As a first example, we will introduce multiple-argument functions as a
distinct object-level construct, as opposed to using currying. A first
attempt at encoding such a construct could be to introduce a
\texttt{list} of term variables at the same time, as follows:

\begin{codequote}
lammany : (list term -> term) -> term.
\end{codequote}

However, this type does not correspond to the construct we are trying to
encode. The type \texttt{list term -> term} introduces a
fresh local variable for the \texttt{list} type, as opposed to a number
of fresh local variables for the \texttt{term} type. Since the HOAS
function space is parametric, there is no way to even refer to the
potential elements of the fresh \texttt{list} -- we can only refer to
the fresh list in full.

Instead, we would like a type that represents all types of the form:
\begin{itemize}
\item \texttt{term} (binding no variables)
\item \texttt{term -> term} (binding a single variable)
\item \texttt{term -> (term -> term)} (binding two variables)
\item \texttt{term -> (term -> (term -> term))} (binding three variables) etc.
\end{itemize}

We can encode such a type inductively in \lamprolog, as follows:

\begin{codequote}
bindmanyterms : type.
bindbase : term -> bindmanyterms.
bindnext : (term -> bindmanyterms) -> bindmanyterms.
\end{codequote}

Furthermore, we can generalize the type that we are binding over, and
the type of the body, leading to a polymorphic type of the form:

\begin{codequote}
bindmany : type -> type -> type.
bindbase : B -> bindmany A B.
bindnext : (A -> bindmany A B) -> bindmany A B.
\end{codequote}

With these, \texttt{lammany} can be encoded as:

\begin{codequote}
lammany : bindmany term term -> term.
\end{codequote}

(As an aside: here we have allowed binding zero variables for
presentation reasons. We could disallow binding zero variables by
changing the \texttt{base} case to require an argument of type
\texttt{A -> B} instead of a \texttt{B}, similar to how we
can specify lists with at least one element inductively by replacing the
\texttt{nil} constructor with a constructor that requires an element.)

How do we work with the \texttt{bindmany} type? For the built-in single
binding type, we used three operations:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  variable substitution, encoded through HOAS function application
\item
  introducing a fresh variable, through the predicate form
  \texttt{x:term -> ...}
\item
  introducing a new assumption, through the predicate form
  \texttt{P -> ...}
\end{itemize}

We can define three equivalent operations as predicates, for the
multiple binding case:

-- \textit{a generalization of application}, for substituting all the variables in
  a \texttt{bindmany}

\begin{codequote}
applymany : bindmany A B -> list A -> B -> prop.
applymany (bindbase Body) [] Body.
applymany (bindnext F) (HD :: TL) Body :-
  applymany (F HD) TL Body.
\end{codequote}

-- \textit{local introduction of multiple fresh variables} at once within a
  predicate P; a list of the variables is passed to it

\begin{codequote}
intromany : bindmany A B -> (list A -> prop) -> prop.
intromany (bindbase _) P :- P [].
intromany (bindnext F) P :-
  (x:A -> intromany (F x) (fun tl => P (x :: tl))).
\end{codequote}

-- \textit{local introduction of a number of assumptions} of the form
  \texttt{P X Y} within a predicate \texttt{Q}. 

This is intended to be used, for example, for introducing assumptions for predicates such as
\texttt{typeof}, taking a list of term variables and a list of types, in the same order.

\begin{codequote}
assumemany : (A -> B -> prop) -> list A -> list B -> prop -> prop.
assumemany P [] [] Q :- Q.
assumemany P (X :: XS) (Y :: YS) Q :- (P X Y -> assumemany P XS YS Q).
\end{codequote}

These predicates are in exact correspondence with the operations we have
available for the built-in HOAS function type -- save for application
being a predicate rather than a term-level construct -- so we are able
to reap the benefits of HOAS representations for multiple bindings as
well.

For convenience, it is also useful to define another predicate that
gives access to both the variables introduced in a \texttt{bindmany} and
the body of the construct as well. This predicate combines
\texttt{intromany}, for introducing the variables, with
\texttt{applymany}, for getting the body of the construct, and is
defined as follows:

\begin{codequote}
openmany : bindmany A B -> (list A -> B -> prop) -> prop.
openmany F P :-
  intromany F (pfun xs => [Body] applymany F xs Body, P xs Body).
\end{codequote}

Two notational idiosyncrasies here of Makam, the \lamprolog dialect we are
using:

\texttt{pfun} is syntactic convenience for anonymous predicate literals,
allowing to use the normal syntax for propositions that we use
elsewhere, i.e.~in clause premises. It is otherwise entirely equivalent
to the \texttt{fun} construct for anonymous functions.

The square bracket notation, used above in \texttt{{[}Body{]}},
introduces a new metavariable; it therefore can be read as existential
quantification. Metavariables are allowed to capture all the free
variables in scope at the point where they are introduced. For most of
them, introduced implicitly in each clause, this means the free
variables in scope when the clause is used. In this case however it is
necessary that \texttt{Body} can capture the fresh variables introduced
by the \texttt{intromany} predicate too, hence the explicit metavariable
introduction.

We can now define the typing rule for \texttt{lammany} using these
predicates, as follows:

\begin{codequote}
arrowmany : list typ -> typ -> typ.

typeof (lammany F) (arrowmany TS T') :-
  openmany F (fun xs body =>
    assumemany typeof xs TS (typeof body T')).
\end{codequote}

For example, the following query returns:

\begin{codequote}
typeof (lammany (bindnext (fun x => bindnext (fun y => bindbase (tuple [x, y]))))) T ?
>> Yes:
>> T := arrowmany [T1, T2] (product [T1, T2])
\end{codequote}

Adding the corresponding \texttt{appmany} construct for simultaneous
application is straightforward. We can use the \texttt{applymany}
predicate defined above to encode simultaneous substitution for the
evaluation rule.

\begin{codequote}
appmany : term -> list term -> term.

typeof (appmany E ES) T' :-
  typeof E (arrowmany TS T'),
  map typeof ES TS.

eval (lammany F) (lammany F).

eval (appmany E ES) V' :-
  eval E (lammany F),
  map eval ES VS,
  applymany F VS E',
  eval E' V'.
\end{codequote}

We can use the \texttt{bindmany} type to encode other constructs, such
as mutually recursive definitions, like the \texttt{let rec} construct
of ML. In that case, we can capture the right binding structure by
introducing a number of variables simultaneously, accessible both when
giving the (same number of) definitions and the body of the construct.

We can therefore encode a \texttt{let rec} construct of the form:

\begin{codequote}
let rec f = f_def and g = g_def in body
\end{codequote}

as

\begin{codequote}
letrec (bindnext (fun f => bindnext (fun g => bindbase ([f_def, g_def]))))
       (bindnext (fun f => bindnext (fun g => bindbase body)))
\end{codequote}

The type-checking rule would be as follows:

\begin{codequote}
letrec : bindmany term (list term) -> bindmany term term -> term.

typeof (letrec XS_Defs XS_Body) T' :-
  openmany XS_Defs (pfun xs defs =>
    assumemany typeof xs TS (map typeof defs TS)
  ),
  openmany XS_Body (pfun xs body =>
    assumemany typeof xs TS (typeof body T')
  ).
\end{codequote}

Still, even though this encoding matches the binding structure correctly, it is unsatisfying, as it
does not guarantee that the same number of variables are introduced in both cases and that the same
number of definitions are given. Though this requirement is enforced at the level of the typing
rules, it would be better if we could enforce it at the syntax level. This would require some sort
of dependency though, which at first does not seem possible to do in \lamprolog.

%% === Complicated binding forms

\section{Complicated binding forms}

The type system of \lamprolog can be viewed as a particular subset of System \fomega: namely, it is the
simply typed lambda calculus extended with prenex polymorphism and simple type constructors of the
form \texttt{type -> type -> ... -> type}. (As an aside, \texttt{prop} can be viewed as a separate
sort, but we take the view that it is just a distinguished extensible type.)

As is well-known from Haskell even before the addition of kind definitions, type promotion and
type-in-type, this subset of System \fomega is enough to model some form of dependency. For example, we
can introduce two types for modelling natural numbers, and define vectors as a GADT using those:

\begin{codequote}
natZ : type.
natS : type -> type.

vector : type -> type -> type.
vnil : vector natZ A.
vcons : A -> vector N A -> vector (natS N) A.
\end{codequote}

In fact, \lamprolog naturally supports pattern-matching over such constructors as well, through
\emph{ad-hoc polymorphism}, where polymorphic type variables are allowed to be instantiated at
\emph{runtime} rather than at type-checking time. The mechanism through which ad-hoc polymorphism
works in \lamprolog is simple: before performing unification at the term-level, we perform unification
at the type level first, therefore further determining any uninstantiated type variables.
Therefore, when we check to see whether the current goal matches the premise of a rule, type
unification can force us to distinguish between different types. Based on these, the standard
example of \texttt{map} for vectors is as follows:

\begin{codequote}
vmap : [A B] (A -> B -> prop) -> vector N A -> vector N B -> prop.
vmap P vnil vnil.
vmap P (vcons X XS) (vcons Y YS) :- P X Y, vmap P XS YS.
\end{codequote}

The notation \texttt{{[}N{]}} in the type of \texttt{vmap} means that the type argument \texttt{N}
is ad-hoc/not-parametric. Non-specified type arguments are parametric by default, so as to match
standard practice in languages like ML and Haskell, and to catch type errors that allowing
unqualified ad-hoc polymorphism would permit. For example, consider the following erroneous
definition for \texttt{fold}, where the arguments for \texttt{P} in the \texttt{cons} case are
flipped.

\begin{codequote}
foldl : (B -> A -> B -> prop) -> B -> list A -> B -> prop.
foldl P S nil S.
foldl P S (cons HD TL) S'' <- P HD S S', foldl P S' TL S''.
\end{codequote}

If ad-hoc polymorphism is allowed for \texttt{A} and \texttt{B}, this is a well-typed
definition. However, the erroneous call to \texttt{P} forces the types \texttt{A} and \texttt{B} to
be unified, and therefore the \texttt{fold} predicate is unnecessarily restricted to only work when
the two types are the same. Having to specify ad-hoc polymorphism explicitly helps us avoid such
mistakes.

Though this support for ad-hoc polymorphism was part of the original \lamprolog design, we have not
found extensive coverage of its implications in the literature. Furthermore, it is not supported
well by standard implementations of \lamprolog (like Teyjus), which was one of the reasons that
prompted us to work on Makam.

Armed with GADTs of this form, we can now introduce dependently-typed binding forms, where the
number of variables that are being bound is reflected in the type. One way to do this is through a
type of the form \texttt{dbind A N B}, standing for a dependently-typed binding of \texttt{N} fresh
variables of type \texttt{A}'s into a body of type \texttt{B}. \texttt{N} will be instantiated with
\texttt{natZ} and \texttt{natS} as above.

\begin{codequote}
dbind : type -> type -> type -> type. 

dbindbase : B -> dbind A natZ B.
dbindnext : (A -> dbind A N B) -> dbind A (natS N) B.
\end{codequote}

Another possibility, avoiding the need for introducing type-level natural numbers, is to use a more
standard type as the dependent parameter: the type of tuples that would serve as substitutions for
the introduced variables. The type would then become:

\begin{codequote}
dbind : type -> type -> type -> type.

dbindbase : B -> dbind A unit B.
dbindnext : (A -> dbind A T B) -> dbind A (A * T) B.
\end{codequote}

The definitions for helper predicates, such as \texttt{intromany}, \texttt{applymany}, etc. follow
the case for \texttt{bindmany} closely, only with more precise types. We first define a helper type
\texttt{subst A T} that is equivalent to the type of tuples \texttt{T} we expect. This is not
strictly necessary but allows for more precise types:

\begin{codequote}
subst : type -> type -> type.
snil : subst A unit.
scons : A -> subst A T -> subst A (A * T).
\end{codequote}

The predicates are now defined as follows. First, their types are:

\begin{codequote}
intromany : [A B] dbind A T B -> (subst A T -> prop) -> prop.
applymany : [A B] dbind A T B -> subst A T -> B -> prop.
openmany : [A B] dbind A T B -> (subst A T -> B -> prop) -> prop.
\end{codequote}

Note that we are reusing the same predicate names as before. Makam allows overloading for all
variable names; expected types are taken into account for resolving variables and disambiguating
between them, as has been long known to be possible in the bi-directional type-checking
literature. Type ascription is used when variable resolution is ambiguous. We also avoid overloading
for constructors; having unambiguous types for constructors means that they can be used to resolve
ambiguity between overloaded predicates easily.

\begin{codequote}
intromany (dbindbase F) P :- P snil.
intromany (dbindnext F) P :-
  (x:A -> intromany (F x) (pfun t => P (scons x t))).

applymany (dbindbase Body) snil Body.
applymany (dbindnext F) (scons X XS) Body :-
  applymany (F X) XS Body.

openmany F P :-
  intromany F (pfun xs => [Body] applymany F xs Body, P xs Body).
\end{codequote}

Also, we define predicates analogous to \texttt{map} and \texttt{assumemany} for the \texttt{subst}
type:

\begin{codequote}
assumemany : (A -> B -> prop) -> subst A T -> subst B T' -> prop -> prop.
assumemany P snil snil Q :- Q.
assumemany P (scons X XS) (scons Y YS) Q :- (P X Y -> assumemany P XS YS Q).

map : [A B] (A -> B -> prop) -> subst A T -> subst B T' -> prop.
map P snil snil.
map P (scons X XS) (scons Y YS) :- P X Y, map P XS YS.
\end{codequote}

(Here we have not captured the relationship between the type of tuples \texttt{T} and \texttt{T'}
precisely, namely that one structurally matches the other with \texttt{A}s replaced by
\texttt{B}s. We could capture that by adding another argument of a dependent type that captures that
relationship, but we will elide this to avoid needlessly complicating the presentation.)

Using this type, we can define \texttt{letrec} as follows:

\begin{codequote}
letrec : dbind term T (subst term T) -> dbind term T term -> term.
\end{codequote}

This encoding captures the binding structure of the construct precisely: we need the same number of
definitions as the number of variables we introduce, and the body of the construct needs exactly the
same number of variables bound.

The typing rule is entirely similar to the one we had previously:

\begin{codequote}
typeof (letrec Defs Body) T' :-
  openmany Defs (pfun xs defs =>
    assumemany typeof xs TS (map typeof defs TS)
  ),
  openmany Body (pfun xs body =>
    assumemany typeof xs TS (typeof body T')
  ).
\end{codequote}

\subsection{Patterns}

We can also use the same `dependency' trick for other, more complicated forms of binding. One such
example which we sketch below is linear ordered binding as in the case of patterns. The point is
that having explicit support in our metalanguage only for single-variable binding, as is standard in
HOAS, together with the two kinds of polymorphism we have shown, is enough. Using them, we can
encode complicated binding forms, that often require explicit support in other meta-linguistic
settings (e.g.~Needle + Knot, Unbound, etc.)

At the top level, a single type argument is needed for patterns, representing the list of variables
that it uses in the order that they are used. Each variable can only be used once, so at the level
of patterns, there is not really a notion of binding: pattern variables are ``introduced'' at their
point of use. However, the list of variables that we build up can be reused in order to be actually
bound into a term -- e.g.~the body of a pattern-matching branch.

(Single-variable binding is really a way to introduce a ``point'' in an AST where we can ``refer
back to'' from its children; or the means to introduce sharing in the notion of ASTs, allowing to
refer to the same ``thing'' a number of times. There's no sharing going on inside patterns though;
hence no binding constructs are needed for encoding the patterns themselves.)

Each sub-pattern that makes up a pattern needs to dependent on two arguments, in order to capture
the linearity -- the fact that variables ``go away'' after their first use. The first argument
represents all the variables that can be used, and initially matches the type argument of the
top-level pattern; the second argument represents the variables that ``remain'' to be used after
this sub-pattern is traversed. We use ``initially'' and ``after'' to refer to the order of visiting
the sub-patterns in a structural, depth-first traversal of the pattern. The ``difference'' between
the types corresponds to the variables that each particular sub-pattern uses.

To make the presentation cleaner, we will introduce a single type for
patterns that has both arguments, with the requirement that for
top-level arguments, no variables remain.

\begin{codequote}
patt : type -> type -> type.
\end{codequote}

\TODO (Probably hidden: add natural numbers so that we can have a simple example of patterns.)

\begin{codequote}
nat : typ.
zero : term.
succ : term -> term.
typeof zero nat.
typeof (succ N) nat :- typeof N nat.
eval zero zero.
eval (succ E) (succ V) :- eval E V.
\end{codequote}

The pattern for zero does not use any variables; the pattern \texttt{succ P} for successor uses the
same variables that \texttt{P} does.
\begin{codequote}
patt_zero : patt T T.
patt_succ : patt T T' -> patt T T'.
\end{codequote}
A single pattern variable declares/uses exactly itself.
\begin{codequote}
patt_var : patt (term * T) T.
\end{codequote}
A wildcard pattern does not use any variables.
\begin{codequote}
patt_wild : patt T T.
\end{codequote}
n-ary tuples require a type for pattern lists:
\begin{codequote}
pattlist : type -> type -> type.
patt_tuple : pattlist T T' -> patt T T'.
patt_nil : pattlist T T.
patt_cons : patt T1 T2 -> pattlist T2 T3 -> pattlist T1 T3.
\end{codequote}

We can now encode a single-branch ``case-or-else'' statement as follows:

\begin{codequote}
case_or_else : term -> patt T unit -> dbind term T term -> term -> term.
\end{codequote}

The first argument is the scrutinee; the second is the pattern; the third is the branch body, where
we bind the same number of variables as the ones used in the pattern, and the last argument is the
\texttt{else} case.

The typing relation for patterns is defined as follows: given a pattern and a list of types for the
variables that remain after the pattern, yield a list of types for all the variables that are
available, plus the type of the pattern.

\begin{codequote}
typeof : patt T T' -> subst typ T'typ -> subst typ Ttyp -> typ -> prop.

typeof patt_var S' (scons T S') T.
typeof patt_wild S S T.
typeof patt_zero S S nat.
typeof (patt_succ P) S' S nat :-
  typeof P S' S nat.

typeof_pattlist : pattlist T T' -> subst typ T'typ -> subst typ Ttyp -> list typ -> prop.

typeof (patt_tuple PS) S' S (product TS) :-
  typeof_pattlist PS S' S TS.

typeof_pattlist patt_nil S S [].
typeof_pattlist (patt_cons P PS) S3 S1 (T :: TS) :-
  typeof_pattlist PS S3 S2 TS, typeof P S2 S1 T.

typeof (case_or_else Scrutinee Pattern Body Else) T' :-
  typeof Scrutinee T,
  typeof Pattern snil TS T,
  openmany Body (pfun xs body =>
     (assumemany typeof xs TS (typeof body T'))
  ),
  typeof Else T'.
\end{codequote}

In order to define evaluation rules, we could define a predicate that models unification between
patterns and terms. However, we can do better than that: we can re-use the existing support for
unification from the metalanguage! In that case, all we need is a way to convert a pattern into a
term, with pattern variables replaced by \emph{meta-level metavariables}. The metavariables are
introduced at each conversion rule as needed, and will get instantiated to the right terms if
unification with the scrutinee succeeds.

\begin{codequote}
patt_to_term : patt T T' -> term -> subst term T' -> subst term T -> prop.
patt_to_term patt_var X Subst (scons X Subst).
patt_to_term patt_wild _ Subst Subst.
patt_to_term patt_zero zero Subst Subst.
patt_to_term (patt_succ PN) (succ EN) Subst' Subst :- patt_to_term PN EN Subst' Subst.

pattlist_to_termlist : pattlist T T' -> list term -> subst term T' -> subst term T -> prop.

patt_to_term (patt_tuple PS) (tuple ES) Subst' Subst :-
  pattlist_to_termlist PS ES Subst' Subst.

pattlist_to_termlist patt_nil [] Subst Subst.
pattlist_to_termlist (patt_cons P PS) (T :: TS) Subst3 Subst1 <-
  pattlist_to_termlist PS TS Subst3 Subst2,
  patt_to_term P T Subst2 Subst1.

eval (case_or_else Scrutinee Pattern Body Else) V :-
  patt_to_term Pattern TermWithUnifvars snil Unifvars,
  if (eq Scrutinee TermWithUnifvars)  (* reuse unification from the meta-language *)
  then (applymany Body Unifvars Body', eval Body' V)
  else (eval Else V).
\end{codequote}

Two new things here: if-then-else has the semantics described in the LogicT monad paper. \texttt{eq}
is a predicate that forces its arguments to be unified, defined simply as:

\begin{codequote}
eq : [A] A -> A -> prop.
eq X X.
\end{codequote}

Example of pattern matching: predecessor for nats.

\begin{codequote}
(eq _PRED 
  (lam _ (fun n => 
    case_or_else n
      (patt_succ patt_var) (dbindnext (fun pred => dbindbase pred))
      zero
      )),
 typeof _PRED T,
 eval (app _PRED zero) PRED_OF_ZERO,
 eval (app _PRED (succ (succ zero))) PRED_OF_TWO) ?
>> Yes:
>> T := arrow nat nat
>> PRED_OF_ZERO := zero
>> PRED_OF_TWO := succ zero
\end{codequote}


%% === Conclusion

\section{Conclusion}

\TODO{} We conclude the paper.

\bibliography{main}

\end{document}
